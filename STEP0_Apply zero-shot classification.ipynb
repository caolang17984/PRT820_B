{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e7e9a-eeb0-4642-abdf-8797cde85076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#\n",
    "# PRT820: THE INFLUENCE OF POST-PUBLICATION CORRESPONDENCE ON RESEARCH PAPERS                #\n",
    "# STUDENT: ANNE TA - S359453                                                                 #\n",
    "# Code Objective: Using Zero-Shot Classification to categorize PPC topics                    #\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "510669b8-e7ec-4e56-b596-a6dbbea841a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------\n",
    "# DEFINE BASIC FUNCTION FOR THE READING DATA FROM FILE\n",
    "#-------------------------------------------------------------\n",
    "import pandas as pd\n",
    "#=======================================\n",
    "# Define global variables for file path\n",
    "#=======================================\n",
    "def get_var(var_name):\n",
    "    variable_filename = \"variable/variable.txt\"\n",
    "    # Read the text file\n",
    "    with open(variable_filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Initialize a dictionary to store the variables\n",
    "    variables = {}\n",
    "\n",
    "    # Process each line in the file\n",
    "    for line in lines:\n",
    "        # Split each line into variable name and value\n",
    "        parts = line.strip().split(',')\n",
    "        if len(parts) == 2:\n",
    "            # Store the variable name and value in the dictionary\n",
    "            variables[parts[0].strip()] = parts[1].strip()\n",
    "\n",
    "    return variables[var_name]\n",
    "\n",
    "#================================================================\n",
    "# Define a function to read data from a CSV file into a DataFrame\n",
    "#================================================================\n",
    "def read_csv(filename, ec='ISO-8859-1'):\n",
    "    try:\n",
    "        # Load CSV data into DataFrame\n",
    "        data_df = pd.read_csv(filename, encoding=ec)\n",
    "        return data_df\n",
    "    \n",
    "    # Handle the case where the file is not found\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please check the file path.\")\n",
    "        \n",
    "    # Handle any other exceptions that might occur during reading the CSV file\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34350e9-a91a-440b-be4b-91702ccf65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Initialize the pipeline classification based on mode facebook/bart-large-mnli\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e38ad8-29b6-4973-97c8-9d1c0be865da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count records:  300\n",
      "After removing duplication:  300\n"
     ]
    }
   ],
   "source": [
    "# Get file path of raw data\n",
    "raw_data_filepath = get_var('raw_data_filepath')\n",
    "# Read file paths from a CSV file into a DataFrame\n",
    "ppc_article_df = read_csv(raw_data_filepath)\n",
    "ppc_df = ppc_article_df.copy()\n",
    "ppc_df = ppc_df[['PPC_DOI', 'Year', 'Abstract']]\n",
    "ppc_df.columns = ['DOI', 'PPC_Year', 'Abstract']\n",
    "print(\"Count records: \", len(ppc_df))\n",
    "ppc_df = ppc_df.drop_duplicates()\n",
    "print(\"After removing duplication: \", len(ppc_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68d5e9de-9437-4170-b4e1-e9726405896a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     26\u001b[0m future_to_doi_title_seq \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(classify_sequence, doi, title, seq): (doi, title, seq) \u001b[38;5;28;01mfor\u001b[39;00m doi, title, seq \u001b[38;5;129;01min\u001b[39;00m ids_and_sequences}\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(future_to_doi_title_seq):\n\u001b[0;32m     28\u001b[0m     doi, title, sequence \u001b[38;5;241m=\u001b[39m future_to_doi_title_seq[future]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\prt820\\Lib\\concurrent\\futures\\_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[1;34m(fs, timeout)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[0;32m    240\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m    241\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[1;32m--> 243\u001b[0m waiter\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mwait(wait_timeout)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\prt820\\Lib\\threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\prt820\\Lib\\threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 355\u001b[0m     waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    356\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Classify sequences using multithreading\u001b[39;00m\n\u001b[0;32m     24\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m     26\u001b[0m     future_to_doi_title_seq \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(classify_sequence, doi, title, seq): (doi, title, seq) \u001b[38;5;28;01mfor\u001b[39;00m doi, title, seq \u001b[38;5;129;01min\u001b[39;00m ids_and_sequences}\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(future_to_doi_title_seq):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\prt820\\Lib\\concurrent\\futures\\_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[1;32m--> 647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshutdown(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\prt820\\Lib\\concurrent\\futures\\thread.py:238\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[1;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[1;32m--> 238\u001b[0m         t\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\prt820\\Lib\\threading.py:1147\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock()\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\prt820\\Lib\\threading.py:1167\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lock\u001b[38;5;241m.\u001b[39macquire(block, timeout):\n\u001b[0;32m   1168\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# Use 'ID' and 'sequence' columns for classification\n",
    "ids_and_sequences = zip(ppc_df['DOI'].tolist(), ppc_df['PPC_Year'].tolist(), ppc_df['Abstract'].tolist())\n",
    "\n",
    "# Define candidate labels\n",
    "candidate_labels = ['agree', 'disagree', 'clarification', 'question', 'recommendation']\n",
    "\n",
    "# Function to exclude text starting with \"©\"\n",
    "def exclude_copyright(text):\n",
    "    return re.sub(r'©.*$', '', text)\n",
    "\n",
    "# Function to classify sequences\n",
    "def classify_sequence(doi, title, sequence_to_classify):\n",
    "    sequence_to_classify = exclude_copyright(sequence_to_classify)\n",
    "    outputs = classifier(sequence_to_classify, candidate_labels)\n",
    "    label_scores = dict(zip(outputs['labels'], outputs['scores']))\n",
    "    label_scores['DOI'] = doi\n",
    "    label_scores['PPC_Year'] = title\n",
    "    label_scores['Abstract'] = sequence_to_classify\n",
    "    return label_scores\n",
    "\n",
    "# Classify sequences using multithreading\n",
    "results = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    future_to_doi_title_seq = {executor.submit(classify_sequence, doi, title, seq): (doi, title, seq) for doi, title, seq in ids_and_sequences}\n",
    "    for future in concurrent.futures.as_completed(future_to_doi_title_seq):\n",
    "        doi, title, sequence = future_to_doi_title_seq[future]\n",
    "        try:\n",
    "            label_scores = future.result()\n",
    "            results.append(label_scores)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to classify sequence for {doi}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "final_df = pd.DataFrame(results)\n",
    "\n",
    "# Reorder columns to match the desired structure\n",
    "final_df = final_df[['DOI', 'PPC_Year', 'Abstract', 'agree', 'clarification', 'question', 'recommendation', 'disagree']]\n",
    "\n",
    "# Store the final results to a CSV file\n",
    "final_df.to_csv(\"result/ppc_abstract_topic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe722278-86d6-46c1-b1bd-eb0f7d7c7746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
